{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Classification\n",
    "\n",
    "Credit risk poses a classification problem that’s inherently imbalanced. This is because healthy loans easily outnumber risky loans. In this Challenge, you’ll use various techniques to train and evaluate models with imbalanced classes. You’ll use a dataset of historical lending activity from a peer-to-peer lending services company to build a model that can identify the creditworthiness of borrowers.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "This challenge consists of the following subsections:\n",
    "\n",
    "* Split the Data into Training and Testing Sets\n",
    "\n",
    "* Create a Logistic Regression Model with the Original Data\n",
    "\n",
    "* Predict a Logistic Regression Model with Resampled Training Data \n",
    "\n",
    "### Split the Data into Training and Testing Sets\n",
    "\n",
    "Open the starter code notebook and then use it to complete the following steps.\n",
    "\n",
    "1. Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame.\n",
    "\n",
    "2. Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns.\n",
    "\n",
    "    > **Note** A value of `0` in the “loan_status” column means that the loan is healthy. A value of `1` means that the loan has a high risk of defaulting.  \n",
    "\n",
    "3. Check the balance of the labels variable (`y`) by using the `value_counts` function.\n",
    "\n",
    "4. Split the data into training and testing datasets by using `train_test_split`.\n",
    "\n",
    "### Create a Logistic Regression Model with the Original Data\n",
    "\n",
    "Employ your knowledge of logistic regression to complete the following steps:\n",
    "\n",
    "1. Fit a logistic regression model by using the training data (`X_train` and `y_train`).\n",
    "\n",
    "2. Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model.\n",
    "\n",
    "3. Evaluate the model’s performance by doing the following:\n",
    "\n",
    "    * Calculate the accuracy score of the model.\n",
    "\n",
    "    * Generate a confusion matrix.\n",
    "\n",
    "    * Print the classification report.\n",
    "\n",
    "4. Answer the following question: How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "### Predict a Logistic Regression Model with Resampled Training Data\n",
    "\n",
    "Did you notice the small number of high-risk loan labels? Perhaps, a model that uses resampled data will perform better. You’ll thus resample the training data and then reevaluate the model. Specifically, you’ll use `RandomOverSampler`.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. \n",
    "\n",
    "2. Use the `LogisticRegression` classifier and the resampled data to fit the model and make predictions.\n",
    "\n",
    "3. Evaluate the model’s performance by doing the following:\n",
    "\n",
    "    * Calculate the accuracy score of the model.\n",
    "\n",
    "    * Generate a confusion matrix.\n",
    "\n",
    "    * Print the classification report.\n",
    "    \n",
    "4. Answer the following question: How well does the logistic regression model, fit with oversampled data, predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "### Write a Credit Risk Analysis Report\n",
    "\n",
    "For this section, you’ll write a brief report that includes a summary and an analysis of the performance of both machine learning models that you used in this challenge. You should write this report as the `README.md` file included in your GitHub repository.\n",
    "\n",
    "Structure your report by using the report template that `Starter_Code.zip` includes, and make sure that it contains the following:\n",
    "\n",
    "1. An overview of the analysis: Explain the purpose of this analysis.\n",
    "\n",
    "\n",
    "2. The results: Using bulleted lists, describe the balanced accuracy scores and the precision and recall scores of both machine learning models.\n",
    "\n",
    "3. A summary: Summarize the results from the machine learning models. Compare the two versions of the dataset predictions. Include your recommendation for the model to use, if any, on the original vs. the resampled data. If you don’t recommend either model, justify your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "# Here we import all the packages and dependencies including two new functions from the \n",
    "# sklearn module and one new function from imblearn module, along with the usual Path function\n",
    "# pathlib and pandas as pd and numpy as np.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77531</th>\n",
       "      <td>19100.0</td>\n",
       "      <td>11.261</td>\n",
       "      <td>86600</td>\n",
       "      <td>0.653580</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>56600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77532</th>\n",
       "      <td>17700.0</td>\n",
       "      <td>10.662</td>\n",
       "      <td>80900</td>\n",
       "      <td>0.629172</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77533</th>\n",
       "      <td>17600.0</td>\n",
       "      <td>10.595</td>\n",
       "      <td>80300</td>\n",
       "      <td>0.626401</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77534</th>\n",
       "      <td>16300.0</td>\n",
       "      <td>10.068</td>\n",
       "      <td>75300</td>\n",
       "      <td>0.601594</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77535</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>9.742</td>\n",
       "      <td>72300</td>\n",
       "      <td>0.585062</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>42300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77536 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "0        10700.0          7.672            52800        0.431818   \n",
       "1         8400.0          6.692            43600        0.311927   \n",
       "2         9000.0          6.963            46100        0.349241   \n",
       "3        10700.0          7.664            52700        0.430740   \n",
       "4        10800.0          7.698            53000        0.433962   \n",
       "...          ...            ...              ...             ...   \n",
       "77531    19100.0         11.261            86600        0.653580   \n",
       "77532    17700.0         10.662            80900        0.629172   \n",
       "77533    17600.0         10.595            80300        0.626401   \n",
       "77534    16300.0         10.068            75300        0.601594   \n",
       "77535    15600.0          9.742            72300        0.585062   \n",
       "\n",
       "       num_of_accounts  derogatory_marks  total_debt  loan_status  \n",
       "0                    5                 1       22800            0  \n",
       "1                    3                 0       13600            0  \n",
       "2                    3                 0       16100            0  \n",
       "3                    5                 1       22700            0  \n",
       "4                    5                 1       23000            0  \n",
       "...                ...               ...         ...          ...  \n",
       "77531               12                 2       56600            1  \n",
       "77532               11                 2       50900            1  \n",
       "77533               11                 2       50300            1  \n",
       "77534               10                 2       45300            1  \n",
       "77535                9                 2       42300            1  \n",
       "\n",
       "[77536 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the Resources folder into a Pandas DataFrame\n",
    "# Here we use the pandas read_csv() function to read in the csv file labeled lending_data.csv. Pandas reads in the data and \n",
    "# turns the data into a dataframe.\n",
    "credit_df = pd.read_csv(Path(\"./Resources/lending_data.csv\"))\n",
    "\n",
    "# Review the DataFrame\n",
    "# Here we call the dataframe so we can review it.\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "\n",
    "# Separate the y variable, the labels\n",
    "# Here we are splitting up the data, in the y variable we assign the column labeled 'loan_status', this is what we are \n",
    "# going to try and predict with the logistic regression model. This is called the target.\n",
    "y = credit_df['loan_status']\n",
    "\n",
    "# Separate the X variable, the features\n",
    "# Here we assign all the columns in the credit_df dataframe to X, less the 'loan_status' colmun, this is acheived with the \n",
    "# .drop() function. So we are saying assign all columns of credit_df but drop the 'loan_status'. This data is the information\n",
    "# that we will ask the module to use to predict the target with. So thats why we give X all the columns of data, so it can\n",
    "# apply the algorithims to the data and give us a prediction.\n",
    "X = credit_df.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the y variable Series\n",
    "# Here we call the variable 'y' to see whats in the series. This is the 'loan_status' column from our original dataframe.\n",
    "# The .head() function returns the first 5 rows in the series.\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  \n",
       "0                 1       22800  \n",
       "1                 0       13600  \n",
       "2                 0       16100  \n",
       "3                 1       22700  \n",
       "4                 1       23000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the X variable DataFrame\n",
    "# Here we review the X variable by calling it. We can see that indeed the loan_status' column has been removed. And\n",
    "# the .head() function returns the first 5 rows in the series.\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check the balance of the labels variable (`y`) by using the `value_counts` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75036\n",
       "1     2500\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "# Its helpful to use the value_counts() function to see how the test & train data is weighted. The majority is 75036\n",
    "# and the minority is 2500. This is an imbalanced class.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_learn module\n",
    "# We import the train_test_split function from the module sklearn.model_selection.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function\n",
    "# Here we split the feature dataset into training and testing sets, then we can fit to a logistic regression model.\n",
    "# The reason we split the data is so the algorithims have some data to learn how to predict the rest of the data that we \n",
    "# want it to predict. The algorithims need something to fit or train with, so we split the data.\n",
    "# The random_state controls the shuffling of the data before it makes the split of data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LogisticRegression module from SKLearn\n",
    "# Here we import the LogisticRegression function from the sklearn.linear_model module.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "# Here we are creating a Logistic Regression function and assign it to a variable named model.\n",
    "model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using training data\n",
    "# Here we are fitting or training the model to the data from the original dataframe. Remember all the columns from the \n",
    "# original dataframe we assigned to X, this is the data that we pass to the model to train with. \n",
    "lr_model = model.fit(X_train, y_train)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction using the testing data\n",
    "# Here we use the .predict() function to predict with the data from the features of credit_df, and we assign it to a new\n",
    "# variable named y_pred for use later. Note, this is where all the work comes together and the model actually makes the predictions\n",
    "# for our target.\n",
    "y_pred = lr_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520479254722232"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model\n",
    "# Here we use the balanced_accuracy_score() function wich calculates the accuracy of our model predictions for the\n",
    "# testing data.\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18663,   102],\n",
       "       [   56,   563]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "# Here we use the confusion_matrix() function and pass as parameters the y_test and y_pred\n",
    "# variables, we get a confusion matrix. This helps us to understand how many predicted true/\n",
    "# actaully true = 18663, predicted false/actually true = 102, predicted false/actually true = 56,\n",
    "# predicted false / actually false = 563. Basically the confusion matrix seperates into 2 columns\n",
    "# all the data that was predicted true and false and wether it was indeed true or false.\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.99      0.91      1.00      0.95      0.91     18765\n",
      "          1       0.85      0.91      0.99      0.88      0.95      0.90       619\n",
      "\n",
      "avg / total       0.99      0.99      0.91      0.99      0.95      0.91     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "# Here we print the classification_report_imbalanced() function, and its helpfull to show us \n",
    "# several metrics, including presicion, recall, F1 and support. We pass both the test data and the \n",
    "# actual prediction data, just like we did for the confusion_matrix(). We are able to glean a lot of\n",
    "# good data from the classification_matrix(), specifically presicion, recall and F1.\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** With the sklearn module we are able to call upon the classification_report() function and get a pretty good idea of how the Logistic Regression algorithim predicted the test and predict data. Here we see the values that the model observed as 0 or healthy loans, 100% of the time the model predicted correctly, and all the values that the model observed as 1 high-risk loans, 85% of the time it predicted them correctly. Also 99% of the time the model predicted that the healthy loans would not default and 91% of the time the high risk loans would default. We know that the training dataset was imbalanced so maybe we can make some adjustments and get the recall and precision higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Logistic Regression Model with Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomOverSampler module form imbalanced-learn\n",
    "# Here we import the RandomOverSampler function from the imblearn.over_sampling module. \n",
    "# RandomOverSampler is a function that randomly samples from the minority dataset to increase\n",
    "# the training dataset to more equal the majority dataset, in an attempt to deal with the imbalanced\n",
    "# sets of data that we are training our model with vrs. the data that we are predicting with. So\n",
    "# the RandomOverSampler over samples from the minority group untill the training dataset equals\n",
    "# the majority.\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the random oversampler model\n",
    "# # Assign a random_state parameter of 1 to the model\n",
    "# Here we instantiate or create a model for oversampling.\n",
    "random_oversampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "# Here we fit or train the oversampler model to all the training data, y_train and X_train.\n",
    "# This represents all the data we have designated as training data.\n",
    "X_resampled, y_resampled = random_oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56271\n",
       "1    56271\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the distinct values of the resampled labels data\n",
    "# This is the value_counts() function and it shows us that since we used the RandomOverSamper \n",
    "# function and oversampled from the minority train dataset, we now have a equal train and test dataset.\n",
    "# Note that we didn't take data from the majority and give it to the minority, instead we randomly over\n",
    "# smpled the minority untill it equalled the majority. For the first model we used, the train dataset\n",
    "# had 2500 values in it, and now that we RandomOverSampled we see that the train sataset has 56271 values\n",
    "# in it.\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `LogisticRegression` classifier and the resampled data to fit the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "# Here we instantiate or create a model to use the LogisticRegression algorithim. \n",
    "resample_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using the resampled training data\n",
    "# And here we fit or train the LogisticRegression model to the X_resampled and y_resampled datasets.\n",
    "lr_resampled_model = resample_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make a prediction using the testing data\n",
    "# Here we actually use the test data and make the prediction by passing the X_test dataset to the \n",
    "# model.\n",
    "y_resampled_pred = lr_resampled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936781215845847"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model \n",
    "# Here we use the balanced_accuracy_score() function and pass it the y_test and y_resampled_pred\n",
    "# datasets as parameters to show us how accurate the prediction was. We can see it was very accurate\n",
    "# with a 99% accuracy_score.\n",
    "balanced_accuracy_score(y_test, y_resampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18649,   116],\n",
       "       [    4,   615]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "# Here again we call on the confusion_matrix() function to show us more in-depth how accurate the model\n",
    "# was. You can see that 18649 loans were predicted healthy and did not default, 116 loans were\n",
    "# unhealthy and did not default. 4 loans were predicted healthy and defaulted and 615 were unhealthy\n",
    "# and defaulted.\n",
    "confusion_matrix(y_test, y_resampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.99      0.99      1.00      0.99      0.99     18765\n",
      "          1       0.84      0.99      0.99      0.91      0.99      0.99       619\n",
      "\n",
      "avg / total       0.99      0.99      0.99      0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "# Here we have the classification_report_imbalanced() funtion and are able to gain more insight\n",
    "# into how our model did. Because I imagine we are most concerned with loans that were initially \n",
    "# labled healthy and defaulted, seen here as 4.\n",
    "print(classification_report_imbalanced(y_test, y_resampled_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model, fit with oversampled data, predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** With the sklearn module we are able to call upon the classification_report() function and get a pretty good idea of how the Logistic Regression algorithim predicted the oversampled data. Here we see the values that the model observed as 0 or healthy loans, 100% of the time the model predicted correctly, and all the values that the model observed as 1 high-risk loans, 84% of the time it predicted them correctly. We can also see under the recall column, 99% of the loans that were healthy did not default and 99% of the loans that were high risk did default. So based on these numbers, I would day that through oversampling the training dataset, we were able to make the model very accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
